[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 aion authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Krzysztof Joachimiak. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Joachimiak K (2022). aion: Time Series keras. R package version 0.1.0.","code":"@Manual{,   title = {aion: Time Series with keras},   author = {Krzysztof Joachimiak},   year = {2022},   note = {R package version 0.1.0}, }"},{"path":"/index.html","id":"aion","dir":"","previous_headings":"","what":"Time Series with keras","title":"Time Series with keras","text":"Temporal Fusion Transformer keras R https://github.com/LongxingTan/Time-series-prediction/blob/master/tfts/layers/nbeats_layer.py","code":""},{"path":"/reference/as_3d_array.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a 3-dimensional array out of a data.frame — as_3d_array","title":"Create a 3-dimensional array out of a data.frame — as_3d_array","text":"Create 3-dimensional array data.frame","code":""},{"path":"/reference/as_3d_array.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a 3-dimensional array out of a data.frame — as_3d_array","text":"","code":"as_3d_array(data, index, key)"},{"path":"/reference/as_3d_array.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a 3-dimensional array out of a data.frame — as_3d_array","text":"","code":"library(tsibbledata) library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union  # We'll use the `global_economy` dataset global_economy #> # A tibble: 15,150 × 9 #>    Country     Code   Year         GDP Growth   CPI Imports Exports Population #>    <fct>       <fct> <dbl>       <dbl>  <dbl> <dbl>   <dbl>   <dbl>      <dbl> #>  1 Afghanistan AFG    1960  537777811.     NA    NA    7.02    4.13    8996351 #>  2 Afghanistan AFG    1961  548888896.     NA    NA    8.10    4.45    9166764 #>  3 Afghanistan AFG    1962  546666678.     NA    NA    9.35    4.88    9345868 #>  4 Afghanistan AFG    1963  751111191.     NA    NA   16.9     9.17    9533954 #>  5 Afghanistan AFG    1964  800000044.     NA    NA   18.1     8.89    9731361 #>  6 Afghanistan AFG    1965 1006666638.     NA    NA   21.4    11.3     9938414 #>  7 Afghanistan AFG    1966 1399999967.     NA    NA   18.6     8.57   10152331 #>  8 Afghanistan AFG    1967 1673333418.     NA    NA   14.2     6.77   10372630 #>  9 Afghanistan AFG    1968 1373333367.     NA    NA   15.2     8.90   10604346 #> 10 Afghanistan AFG    1969 1408888922.     NA    NA   15.0    10.1    10854428 #> # … with 15,140 more rows  selected_ge <-  global_economy %>%  select(Country, Year, Imports, Exports)"},{"path":"/reference/layer_glu.html","id":null,"dir":"Reference","previous_headings":"","what":"Gated Linear Unit — layer_glu","title":"Gated Linear Unit — layer_glu","text":"form introduced Language modeling gated convolutional networks Dauphin et al., used sequence processing tasks compared gating mechanism used LSTM layers. context time series processing explicitly proposed Temporal Fusion Transformer.","code":""},{"path":"/reference/layer_glu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gated Linear Unit — layer_glu","text":"","code":"layer_glu(object, units, activation = NULL, return_gate = FALSE, ...)"},{"path":"/reference/layer_glu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gated Linear Unit — layer_glu","text":"object compose new Layer instance . Typically Sequential model Tensor (e.g., returned layer_input()). return value depends object. object : missing NULL, Layer instance returned. Sequential model, model additional layer returned. Tensor, output tensor layer_instance(object) returned. units Positive integer, dimensionality output space. activation Name activation function use. specify anything, activation applied (ie. \"linear\" activation: (x) = x). return_gate Logical - return gate values. Default: FALSE","code":""},{"path":"/reference/layer_glu.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gated Linear Unit — layer_glu","text":"Tensor shape (batch_size, ..., units). Optionally, can also return weights tensor identical shape.","code":""},{"path":"/reference/layer_glu.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gated Linear Unit — layer_glu","text":"Computed according equation: $$GLU(\\gamma) = \\sigma(W\\gamma + b) \\odot (V\\gamma + c)$$","code":""},{"path":"/reference/layer_glu.html","id":"input-and-output-shapes","dir":"Reference","previous_headings":"","what":"Input and Output Shapes","title":"Gated Linear Unit — layer_glu","text":"Input shape: nD tensor shape: (batch_size, ..., input_dim). common situation 2D input shape (batch_size, input_dim). Output shape: nD tensor shape: (batch_size, ..., units). instance, 2D input shape (batch_size, input_dim), output shape (batch_size, unit).","code":""},{"path":"/reference/layer_glu.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gated Linear Unit — layer_glu","text":"Dauphin, Yann N., et al. (2017). Language modeling gated convolutional networks.. International conference machine learning. PMLR Lim, Bryan et al. (2019). Temporal Fusion Transformers Interpretable Multi-horizon Time Series Forecasting. arXiv Implementation PyTorch Jan Beitner Implementation PyTorch Playtika Research","code":""},{"path":"/reference/layer_glu.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gated Linear Unit — layer_glu","text":"","code":"library(keras)  # ================================================================ #             SEQUENTIAL MODEL, NO GATE VALUES RETURNED # ================================================================  model <-   keras_model_sequential() %>%   layer_glu(10, input_shape = 30) #> Loaded Tensorflow version 2.7.0  model #> Model: \"sequential\" #> ________________________________________________________________________________ #>  Layer (type)                       Output Shape                    Param #      #> ================================================================================ #>  glu (GLU)                          (None, 10)                      620          #> ================================================================================ #> Total params: 620 #> Trainable params: 620 #> Non-trainable params: 0 #> ________________________________________________________________________________  output <- model(matrix(1, 32, 30)) dim(output) #> [1] 32 10 output[1,] #> tf.Tensor( #> [ 0.94915634 -0.8341388  -0.5819986  -0.11771909 -0.05401173 -0.5836786 #>  -0.1255717   0.15330873  0.5109574   1.2039927 ], shape=(10,), dtype=float32)  # ================================================================ #                     WITH GATE VALUES RETURNED # ================================================================  inp  <- layer_input(30) out  <- layer_glu(units = 10, return_gate = TRUE)(inp)  model <- keras_model(inp, out)  model #> Model: \"model\" #> ________________________________________________________________________________ #>  Layer (type)                       Output Shape                    Param #      #> ================================================================================ #>  input_1 (InputLayer)               [(None, 30)]                    0            #>  glu_1 (GLU)                        [(None, 10),                    620          #>                                      (None, 10)]                                 #> ================================================================================ #> Total params: 620 #> Trainable params: 620 #> Non-trainable params: 0 #> ________________________________________________________________________________  c(values, gate) %<-% model(matrix(1, 32, 30)) dim(values) #> [1] 32 10 dim(gate) #> [1] 32 10  values[1,] #> tf.Tensor( #> [-0.46539044 -0.48927456 -0.22954868 -0.43084416  0.55501723  0.18934621 #>  -0.7245728   0.1265519   0.2939192  -0.32936743], shape=(10,), dtype=float32) gate[1,] #> tf.Tensor( #> [0.55341357 0.6830228  0.13582468 0.8568422  0.32849157 0.2516095 #>  0.4454018  0.20950854 0.42199287 0.43707   ], shape=(10,), dtype=float32)"},{"path":"/reference/layer_grn.html","id":null,"dir":"Reference","previous_headings":"","what":"Gated Residual Network block — layer_grn","title":"Gated Residual Network block — layer_grn","text":"GRN one elements TFT model composed . expected benefit applying value better ability switching linear non-linear processing.","code":""},{"path":"/reference/layer_grn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gated Residual Network block — layer_grn","text":"","code":"layer_grn(   object,   hidden_units,   output_size = hidden_units,   dropout_rate = NULL,   use_context = FALSE,   return_gate = FALSE,   ... )"},{"path":"/reference/layer_grn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gated Residual Network block — layer_grn","text":"object compose new Layer instance . Typically Sequential model Tensor (e.g., returned layer_input()). return value depends object. object : missing NULL, Layer instance returned. Sequential model, model additional layer returned. Tensor, output tensor layer_instance(object) returned. hidden_units Size hidden layer. output_size Dimensionality output feature space. use_context Use additional (static) context. TRUE, additional layer created handle context input. return_gate Logical - return gate values. Default: FALSE","code":""},{"path":"/reference/layer_grn.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gated Residual Network block — layer_grn","text":"output computed : $$GRN(,c) = LayerNorm(+ GLU({\\eta}_1))$$ $${\\eta}_1 = W_1\\eta_2 + b_1$$ $$\\eta_2 = ELU(W_2a + W_3c + b_2)$$","code":""},{"path":"/reference/layer_grn.html","id":"input-and-output-shapes","dir":"Reference","previous_headings":"","what":"Input and Output Shapes","title":"Gated Residual Network block — layer_grn","text":"Input shape: nD tensor shape: (batch_size, ..., input_dim). common situation 2D input shape (batch_size, input_dim). Output shape: nD tensor shape: (batch_size, ..., units). instance, 2D input shape (batch_size, input_dim), output shape (batch_size, unit).","code":""},{"path":"/reference/layer_grn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gated Residual Network block — layer_grn","text":"","code":"library(keras)  # ================================================================ #             SEQUENTIAL MODEL, NO GATE VALUES RETURNED # ================================================================  model <-   keras_model_sequential() %>%   layer_grn(10, input_shape = 30)  model #> Model: \"sequential_1\" #> ________________________________________________________________________________ #>  Layer (type)                       Output Shape                    Param #      #> ================================================================================ #>  grn (GRN)                          (None, 10)                      970          #> ================================================================================ #> Total params: 970 #> Trainable params: 970 #> Non-trainable params: 0 #> ________________________________________________________________________________  output <- model(matrix(1, 32, 30)) dim(output) #> [1] 32 10 output[1,] #> tf.Tensor( #> [-2.2255864   1.3665725  -0.766042    0.3830403  -0.45475054 -0.01936769 #>   1.4788612  -0.01041254  0.20966543  0.03802004], shape=(10,), dtype=float32)  #'================================================================ #            WITH GATE VALUES AND ADDITIONAL CONTEXT # ================================================================  inp  <- layer_input(c(28, 5)) ctx  <- layer_input(10) out  <- layer_grn(             hidden_units = 10,             return_gate = TRUE,             use_context = TRUE          )(inp, context = ctx)  model <- keras_model(list(inp, ctx), out)  model #> Model: \"model_1\" #> ________________________________________________________________________________ #>  Layer (type)             Output Shape      Param #  Connected to                #> ================================================================================ #>  input_2 (InputLayer)     [(None, 28, 5)]   0        []                          #>  input_3 (InputLayer)     [(None, 10)]      0        []                          #>  grn_1 (GRN)              [(None, 28, 10),  570      ['input_2[0][0]',           #>                            (None, 28, 10)]            'input_3[0][0]']           #> ================================================================================ #> Total params: 570 #> Trainable params: 570 #> Non-trainable params: 0 #> ________________________________________________________________________________  arr_1 <- array(1, dim = c(1, 28, 5)) arr_2 <- array(1, dim = c(1, 10))  c(values, gate) %<-% model(list(arr_1, arr_2)) dim(values) #> [1]  1 28 10 dim(gate) #> [1]  1 28 10  values[1, all_dims()] #> Error in all_dims(): could not find function \"all_dims\" gate[1, all_dims()] #> Error in all_dims(): could not find function \"all_dims\""},{"path":"/reference/layer_interpretable_mh_attention.html","id":null,"dir":"Reference","previous_headings":"","what":"Interpretable multi-head attention layer — layer_interpretable_mh_attention","title":"Interpretable multi-head attention layer — layer_interpretable_mh_attention","text":"Interpretable multi-head attention layer","code":""},{"path":"/reference/layer_interpretable_mh_attention.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interpretable multi-head attention layer — layer_interpretable_mh_attention","text":"","code":"layer_interpretable_mh_attention(   object,   state_size,   num_heads,   dropout_rate = 0,   ... )"},{"path":"/reference/layer_interpretable_mh_attention.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interpretable multi-head attention layer — layer_interpretable_mh_attention","text":"num_heads Number attention heads. dropout_rate Dropout rate","code":""},{"path":"/reference/layer_interpretable_mh_attention.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Interpretable multi-head attention layer — layer_interpretable_mh_attention","text":"TFT original implementation Google","code":""},{"path":"/reference/layer_interpretable_mh_attention.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interpretable multi-head attention layer — layer_interpretable_mh_attention","text":"","code":"lookback   <- 28 horizon    <- 14 all_steps  <- lookback + horizon state_size <- 5  queries <- layer_input(c(horizon, state_size)) keys    <- layer_input(c(all_steps, state_size)) values  <- layer_input(c(all_steps, state_size))  imh_attention <-    layer_interpretable_mh_attention(       state_size = state_size, num_heads = 10    )(queries, keys, values)"},{"path":"/reference/layer_lmu.html","id":null,"dir":"Reference","previous_headings":"","what":"Legendre Memory Unit layer — layer_lmu","title":"Legendre Memory Unit layer — layer_lmu","text":"layer trainable low-dimensional delay systems. unit buffers encoded input internally representing low-dimensional (.e., compressed) version sliding window. Nonlinear decodings representation, expressed B matrices, provide computations across window, derivative, energy, median value, etc (1, 2). Note decoder matrices can span across units input sequence.","code":""},{"path":"/reference/layer_lmu.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Legendre Memory Unit layer — layer_lmu","text":"","code":"layer_lmu(   object,   memory_d,   order,   theta,   hidden_cell,   trainable_theta = FALSE,   hidden_to_memory = FALSE,   memory_to_memory = FALSE,   input_to_hidden = FALSE,   discretizer = \"zoh\",   kernel_initializer = \"glorot_uniform\",   recurrent_initializer = \"orthogonal\",   kernel_regularizer = NULL,   recurrent_regularizer = NULL,   use_bias = FALSE,   bias_initializer = \"zeros\",   bias_regularizer = NULL,   dropout = 0,   recurrent_dropout = 0,   return_sequences = FALSE,   ... )"},{"path":"/reference/layer_lmu.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Legendre Memory Unit layer — layer_lmu","text":"memory_d Dimensionality input memory component. order number degrees transfer function LTI system used represent sliding window history. parameter sets number Legendre polynomials used orthogonally represent sliding window. theta number timesteps sliding window represented using LTI system. context, sliding window represents dynamic range data, fixed size, used predict value next time step. value smaller size input sequence, number steps represented time prediction, however entire sequence still processed order information projected hidden layer. trainable_theta enabled, theta updated course training. hidden_cell Keras Layer/RNNCell implementing hidden component. trainable_theta TRUE, theta learnt course training. Otherwise, kept constant. hidden_to_memory TRUE, connect output hidden component back memory component (default FALSE). memory_to_memory TRUE, add learnable recurrent connection (addition static input_to_hidden TRUE, connect input directly hidden component (addition discretizer method used discretize B matrices LMU. Current options \"zoh\" (short Zero Order Hold) \"euler\". \"zoh\" accurate, training slower \"euler\" trainable_theta=TRUE. Note larger theta needed discretizing using \"euler\" (value larger 4*order recommended). kernel_initializer Initializer weights input memory/hidden component. NULL, weights used, input size must match memory/hidden size. recurrent_initializer Initializer memory_to_memory weights (connection enabled). kernel_regularizer Regularizer weights input memory/hidden component. recurrent_regularizer Regularizer memory_to_memory weights (connection enabled). use_bias TRUE, memory component includes bias term. bias_initializer Initializer memory component bias term. used use_bias=TRUE. bias_regularizer Regularizer memory component bias term. used use_bias=TRUE. dropout Dropout rate input connections. recurrent_dropout Dropout rate memory_to_memory connection. return_sequences TRUE, return full output sequence. Otherwise, return just last output output sequence.","code":""},{"path":"/reference/layer_lmu.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Legendre Memory Unit layer — layer_lmu","text":"Voelker Eliasmith (2018). Improving spiking dynamical networks: Accurate delays, higher-order synapses, time cells. Neural Computation, 30(3): 569-609. 2.Voelker Eliasmith. \"Methods systems implementing dynamic neural networks.\" U.S. Patent Application . 15/243,223.","code":""},{"path":"/reference/layer_multi_dense.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiple dense layers in one layer — layer_multi_dense","title":"Multiple dense layers in one layer — layer_multi_dense","text":"Multiple dense layers one layer","code":""},{"path":"/reference/layer_multi_dense.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiple dense layers in one layer — layer_multi_dense","text":"","code":"layer_multi_dense(object, units, new_dim = FALSE, ...)"},{"path":"/reference/layer_multi_dense.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiple dense layers in one layer — layer_multi_dense","text":"object compose new Layer instance . Typically Sequential model Tensor (e.g., returned layer_input()). return value depends object. object : missing NULL, Layer instance returned. Sequential model, model additional layer returned. Tensor, output tensor layer_instance(object) returned. units Positive integer, dimensionality output space.","code":""},{"path":"/reference/layer_multi_dense.html","id":"input-and-output-shapes","dir":"Reference","previous_headings":"","what":"Input and Output Shapes","title":"Multiple dense layers in one layer — layer_multi_dense","text":"Input shape: nD tensor shape: (batch_size, ..., input_dim). common situation 2D input shape (batch_size, input_dim). Output shape: length units equals 1 nD tensor shape: (batch_size, ..., units). instance, 2D input shape (batch_size, input_dim), output shape (batch_size, unit). length units greater 1 nD tensor shape: (batch_size, ..., units). instance, 2D input shape (batch_size, input_dim), output shape (batch_size, unit).","code":""},{"path":"/reference/layer_multi_dense.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multiple dense layers in one layer — layer_multi_dense","text":"","code":"# ========================================================================== #                          SIMPLE CONCATENATION # ==========================================================================  inp <- layer_input(c(28, 3)) md <- layer_multi_dense(units = c(4, 6, 8))(inp) #> Error in py_call_impl(callable, dots$args, dots$keywords): RuntimeError: Evaluation error: object '.units' not found.  md_model <- keras_model(inp, md) #> Error in py_resolve_dots(list(...)): object 'md' not found  dummy_input <- array(1, dim = c(1, 28, 3))  out <- md_model(dummy_input) #> Error in md_model(dummy_input): could not find function \"md_model\" dim(out) #> Error in eval(expr, envir, enclos): object 'out' not found  # ========================================================================== #                          NEW DIMESNION # ==========================================================================  inp <- layer_input(c(28, 3)) md <- layer_multi_dense(units = 5, new_dim = TRUE)(inp)  md_model <- keras_model(inp, md)  dummy_input <- array(1, dim = c(1, 28, 3))  out <- md_model(dummy_input) dim(out) #> [1]  1 28  3  5"},{"path":"/reference/layer_multi_embedding.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiple embeddings in one layer — layer_multi_embedding","title":"Multiple embeddings in one layer — layer_multi_embedding","text":"Multiple embeddings one layer","code":""},{"path":"/reference/layer_multi_embedding.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiple embeddings in one layer — layer_multi_embedding","text":"","code":"layer_multi_embedding(object, input_dims, output_dims, new_dim = FALSE, ...)"},{"path":"/reference/layer_multi_embedding.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiple embeddings in one layer — layer_multi_embedding","text":"object compose new Layer instance . Typically Sequential model Tensor (e.g., returned layer_input()). return value depends object. object : missing NULL, Layer instance returned. Sequential model, model additional layer returned. Tensor, output tensor layer_instance(object) returned. new_dim TRUE, new dimension created instead stacking outputs dimension","code":""},{"path":"/reference/layer_multi_embedding.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multiple embeddings in one layer — layer_multi_embedding","text":"","code":"# ========================================================================== #                          SIMPLE CONCATENATION # ==========================================================================  inp <- layer_input(c(28, 3)) emb <- layer_multi_embedding(input_dims = c(4, 6, 8), output_dims = c(3, 4, 5))(inp)  emb_model <- keras_model(inp, emb)  dummy_input <- array(1, dim = c(1, 28, 3)) dummy_input[,,1] <- sample(4,size = 28, replace = TRUE) dummy_input[,,2] <- sample(6,size = 28, replace = TRUE) dummy_input[,,3] <- sample(8,size = 28, replace = TRUE)  out <- emb_model(dummy_input) dim(out) #> [1]  1 28 12  # ========================================================================== #                          NEW DIMESNION # ==========================================================================  inp <- layer_input(c(28, 3)) emb <- layer_multi_embedding(input_dims = c(4, 6, 8), output_dims = 5, new_dim = TRUE)(inp)  emb_model <- keras_model(inp, emb)  dummy_input <- array(1, dim = c(1, 28, 3)) dummy_input[,,1] <- sample(4,size = 28, replace = TRUE) dummy_input[,,2] <- sample(6,size = 28, replace = TRUE) dummy_input[,,3] <- sample(8,size = 28, replace = TRUE)  out <- emb_model(dummy_input) dim(out) #> [1]  1 28  3  5"},{"path":"/reference/layer_scaled_dot_attention.html","id":null,"dir":"Reference","previous_headings":"","what":"Scaled dot product attention layer — layer_scaled_dot_attention","title":"Scaled dot product attention layer — layer_scaled_dot_attention","text":"Introduced Attention Need. Defined :","code":""},{"path":"/reference/layer_scaled_dot_attention.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Scaled dot product attention layer — layer_scaled_dot_attention","text":"","code":"layer_scaled_dot_attention(object, dropout_rate = 0, ...)"},{"path":"/reference/layer_scaled_dot_attention.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Scaled dot product attention layer — layer_scaled_dot_attention","text":"dropout_rate Dropout rate","code":""},{"path":"/reference/layer_scaled_dot_attention.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Scaled dot product attention layer — layer_scaled_dot_attention","text":"$$Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V$$ Originally, dropout specified . added inside layer Temporal Fusion Transformer implementation Google. component Multi-Head Attention Layers (well interpretable version, available aion package).","code":""},{"path":"/reference/layer_scaled_dot_attention.html","id":"call-arguments","dir":"Reference","previous_headings":"","what":"Call arguments","title":"Scaled dot product attention layer — layer_scaled_dot_attention","text":"query: Query Tensor shape [B, T, dim]. value: Value Tensor shape [B, S, dim]. key: Optional key Tensor shape [B, S, dim]. given, use value key value, common case. attention_mask: boolean mask shape [B, T, S], prevents attention certain positions. return_attention_scores: boolean indicate whether output attention output TRUE, (attention_output, attention_scores) FALSE. Defaults FALSE. training: Python boolean indicating whether layer behave training mode (adding dropout) inference mode (dropout). Defaults either using training mode parent layer/model, FALSE (inference) parent layer.","code":""},{"path":"/reference/layer_scaled_dot_attention.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Scaled dot product attention layer — layer_scaled_dot_attention","text":"Attention Need.","code":""},{"path":"/reference/layer_scaled_dot_attention.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Scaled dot product attention layer — layer_scaled_dot_attention","text":"","code":"lookback   <- 28 horizon    <- 14 all_steps  <- lookback + horizon state_size <- 5  queries <- layer_input(c(horizon, state_size)) keys    <- layer_input(c(all_steps, state_size)) values  <- layer_input(c(all_steps, state_size))  sdp_attention <- layer_scaled_dot_attention()(queries, keys, values)"},{"path":"/reference/layer_tcn.html","id":null,"dir":"Reference","previous_headings":"","what":"Residual block for the WaveNet TCN — layer_tcn","title":"Residual block for the WaveNet TCN — layer_tcn","text":"Residual block WaveNet TCN","code":""},{"path":"/reference/layer_tcn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Residual block for the WaveNet TCN — layer_tcn","text":"","code":"layer_tcn(   object,   nb_filters = 64,   kernel_size = 3,   nb_stacks = 1,   dilations = c(1, 7, 14),   padding = \"causal\",   use_skip_connections = TRUE,   dropout_rate = 0,   return_sequences = FALSE,   activation = \"relu\",   kernel_initializer = \"he_normal\",   use_batch_norm = FALSE,   use_layer_norm = FALSE,   use_weight_norm = FALSE,   input_shape = NULL,   ... )"},{"path":"/reference/layer_tcn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Residual block for the WaveNet TCN — layer_tcn","text":"nb_filters number convolutional filters use block kernel_size size convolutional kernel padding padding used convolutional layers, '' 'causal'. dropout_rate Float 0 1. Fraction input units drop. activation final activation used o = Activation(x + F(x)) kernel_initializer Initializer kernel weights matrix (Conv1D). use_batch_norm Whether use batch normalization residual layers . use_layer_norm Whether use layer normalization residual layers . use_weight_norm Whether use weight normalization residual layers . dilation_rate dilation power 2 using residual block","code":""},{"path":"/reference/layer_temporal_fusion_decoder.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporal Fusion Decoder layer — layer_temporal_fusion_decoder","title":"Temporal Fusion Decoder layer — layer_temporal_fusion_decoder","text":"One blocks, TFT model consists . call, accepts two parameters: output LSTM static context LSTM output enriched static context features additionally processed ath end.","code":""},{"path":"/reference/layer_temporal_fusion_decoder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporal Fusion Decoder layer — layer_temporal_fusion_decoder","text":"","code":"layer_temporal_fusion_decoder(   object,   hidden_units,   state_size,   dropout_rate = 0,   use_context,   num_heads,   ... )"},{"path":"/reference/layer_temporal_fusion_decoder.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temporal Fusion Decoder layer — layer_temporal_fusion_decoder","text":"","code":"lookback   <- 28 horizon    <- 14 all_steps  <- lookback + horizon state_size <- 5  lstm_output <- layer_input(c(all_steps, state_size)) context     <- layer_input(state_size)  # No attentiion scores returned tdf <- layer_temporal_fusion_decoder(    hidden_units = 30,    state_size = state_size,    use_context = TRUE,    num_heads = 10 )(lstm_output, context)  # With attention scores c(tfd, attention_scores) %<-%    layer_temporal_fusion_decoder(       hidden_units = 30,       state_size = state_size,       use_context = TRUE,       num_heads = 10    )(lstm_output, context, return_attention_scores=TRUE)"},{"path":"/reference/layer_vsn.html","id":null,"dir":"Reference","previous_headings":"","what":"Variable Selection Network block — layer_vsn","title":"Variable Selection Network block — layer_vsn","text":"receives four-dimensional vector input case dynamic data (batch_size, timesteps, n_features, feature_dim)","code":""},{"path":"/reference/layer_vsn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variable Selection Network block — layer_vsn","text":"","code":"layer_vsn(   object,   hidden_units,   state_size,   dropout_rate = NULL,   use_context = FALSE,   return_weights = FALSE,   ... )"},{"path":"/reference/layer_vsn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variable Selection Network block — layer_vsn","text":"state_size Dimensionality feature space, common across model. name comes original paper also refer $$d_model$$ return_weights Return weights selection.","code":""},{"path":"/reference/layer_vsn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variable Selection Network block — layer_vsn","text":"tensor shapes: dynamic data - (batch_size, timesteps, state_size) static data - (batch_size, state_size)","code":""},{"path":"/reference/layer_vsn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Variable Selection Network block — layer_vsn","text":"","code":"# ========================================================================= #               THREE-DIMENSIONAL INPUT (STATIC FEATURES) # =========================================================================  # input: (batch_size, n_features, state_size)  inp <- layer_input(c(10, 5)) out <- layer_vsn(hidden_units = 10, state_size = 5)(inp) dim(out) #> [1] NA  5  # ========================================================================= #               FOUR-DIMENSIONAL INPUT (DYNAMIC FEATURES) # =========================================================================  # input: (batch_size, timesteps, n_features, state_size)  inp <- layer_input(c(28, 10, 5)) out <- layer_vsn(hidden_units = 10, state_size = 5)(inp) dim(out) #> [1] NA 28  5"},{"path":"/reference/loss_negative_log_likelihood.html","id":null,"dir":"Reference","previous_headings":"","what":"General negative log likelihood loss function — loss_negative_log_likelihood","title":"General negative log likelihood loss function — loss_negative_log_likelihood","text":"General negative log likelihood loss function","code":""},{"path":"/reference/loss_negative_log_likelihood.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"General negative log likelihood loss function — loss_negative_log_likelihood","text":"","code":"loss_negative_log_likelihood(...)"},{"path":"/reference/loss_negative_log_likelihood.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"General negative log likelihood loss function — loss_negative_log_likelihood","text":"distribution probability distribution function tfprobability package.","code":""},{"path":"/reference/loss_negative_log_likelihood.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"General negative log likelihood loss function — loss_negative_log_likelihood","text":"","code":"y_pred <- array(runif(60), c(2, 10, 2)) y_true <- array(runif(20), c(2, 10, 1))  # As a callable object loss_negative_log_likelihood(reduction = 'auto')(y_true, y_pred) #> Error in py_call_impl(x, dots$args, dots$keywords): RuntimeError: Evaluation error: .onLoad failed in loadNamespace() for 'tfprobability', details: #>   call: py_module_import(module, convert = convert) #>   error: ImportError: This version of TensorFlow Probability requires TensorFlow version >= 2.8; Detected an installation of version 2.7.0. Please upgrade TensorFlow to proceed. #> . loss_negative_log_likelihood(reduction = 'sum')(y_true, y_pred) #> Error in py_call_impl(x, dots$args, dots$keywords): RuntimeError: Evaluation error: .onLoad failed in loadNamespace() for 'tfprobability', details: #>   call: py_module_import(module, convert = convert) #>   error: ImportError: This version of TensorFlow Probability requires TensorFlow version >= 2.8; Detected an installation of version 2.7.0. Please upgrade TensorFlow to proceed. #> ."},{"path":"/reference/loss_quantile.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile (Pinball) loss function — loss_quantile","title":"Quantile (Pinball) loss function — loss_quantile","text":"generalized version quantile loss. model can predict multiple quantiles .","code":""},{"path":"/reference/loss_quantile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile (Pinball) loss function — loss_quantile","text":"","code":"loss_quantile(...)  loss_pinball(...)"},{"path":"/reference/loss_quantile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile (Pinball) loss function — loss_quantile","text":"quantiles List quantiles (numeric vector values 0 1).","code":""},{"path":"/reference/loss_quantile.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quantile (Pinball) loss function — loss_quantile","text":"Loss value single sample-timestep-quantile computed : $$QL(y_t, \\hat{y}_t, q) = max(q(y_t - \\hat{y}_t), (q - 1)(y_t - \\hat{y}_t))$$ equivalently : $$QL(y_t, \\hat{y}_t, q) = max(q(y_t - \\hat{y}_t), 0) +  max((1 - q)(\\hat{y}_t - y_t), 0)$$ multiple quantiles defined, generalized, averaged loss computed according equation: $$\\mathcal{L}(\\Omega, W) = \\Sigma_{y_t \\\\Omega}\\Sigma_{q \\\\mathcal{Q}}\\Sigma^{\\tau_{max}}_{\\tau=1} = \\frac{QL(y_t, \\hat{y}(q, t - \\tau, \\tau), q)}{M_{\\tau_{max}}}$$ loss function computed reduction = 'auto reduction = 'mean'.","code":""},{"path":"/reference/loss_quantile.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Quantile (Pinball) loss function — loss_quantile","text":"moment, can use loss_quantile instantiate class call directly like loss keras. Please see: #1342 issue","code":""},{"path":"/reference/loss_quantile.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Quantile (Pinball) loss function — loss_quantile","text":"Quantile loss function machine learning Pinball loss function (Lokad) Temporal Fusion Transformer Original TFT implementation Google","code":""},{"path":"/reference/loss_quantile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile (Pinball) loss function — loss_quantile","text":"","code":"y_pred <- array(runif(60), c(2, 10, 3)) y_true <- array(runif(20), c(2, 10, 1))  # As a callable object loss_quantile(quantiles = c(0.1, 0.5, 0.9), reduction = 'auto')(y_true, y_pred) #> tf.Tensor(0.1699584, shape=(), dtype=float32) loss_quantile(quantiles = c(0.1, 0.5, 0.9), reduction = 'sum')(y_true, y_pred) #> tf.Tensor(10.197504, shape=(), dtype=float32)"},{"path":"/reference/loss_tweedie.html","id":null,"dir":"Reference","previous_headings":"","what":"Tweedie Loss (negative log likelihood) — loss_tweedie","title":"Tweedie Loss (negative log likelihood) — loss_tweedie","text":"Tweedie Loss (negative log likelihood)","code":""},{"path":"/reference/loss_tweedie.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tweedie Loss (negative log likelihood) — loss_tweedie","text":"","code":"loss_tweedie(...)"},{"path":"/reference/loss_tweedie.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tweedie Loss (negative log likelihood) — loss_tweedie","text":"p Power parameter 0, 2 range. allows choose desired distribution Tweedie distributions family.","code":""},{"path":"/reference/loss_tweedie.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Tweedie Loss (negative log likelihood) — loss_tweedie","text":"moment, can use loss_quantile instantiate class call directly like loss keras. Please see: #1342 issue","code":""},{"path":"/reference/loss_tweedie.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Tweedie Loss (negative log likelihood) — loss_tweedie","text":"Tweedie Loss Function p parameter","code":""},{"path":"/reference/loss_tweedie.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tweedie Loss (negative log likelihood) — loss_tweedie","text":"","code":"y_pred <- array(runif(60), c(2, 10, 1)) y_true <- array(runif(20), c(2, 10, 1))  # As a callable object loss_tweedie(p = 1.5, reduction = 'auto')(y_true, y_pred) #> tf.Tensor(3.395822048187256, shape=(), dtype=float64) loss_tweedie(p = 1.5, reduction = 'sum')(y_true, y_pred) #> tf.Tensor(67.91644287109375, shape=(), dtype=float64)"},{"path":"/reference/metric_q_risk.html","id":null,"dir":"Reference","previous_headings":"","what":"q-Risk metric — metric_q_risk","title":"q-Risk metric — metric_q_risk","text":"q-Risk metric","code":""},{"path":"/reference/metric_q_risk.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"q-Risk metric — metric_q_risk","text":"","code":"metric_q_risk(...)"},{"path":"/reference/model_tft.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporal Fusion Transformer model — model_tft","title":"Temporal Fusion Transformer model — model_tft","text":"Temporal Fusion Transformer model","code":""},{"path":"/reference/model_tft.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporal Fusion Transformer model — model_tft","text":"","code":"model_tft(...)"},{"path":"/reference/model_tft.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporal Fusion Transformer model — model_tft","text":"lookback Number timesteps past horizon Forecast length (number timesteps) past_numeric_size Number numeric features past past_categorical_size Number categorical features past future_numeric_size Number numeric features future","code":""},{"path":"/reference/model_tft.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temporal Fusion Transformer model — model_tft","text":"","code":"tft <- model_tft(    lookback                = 28,    horizon                 = 14,    past_numeric_size       = 5,    past_categorical_size   = 2,    future_numeric_size     = 4,    future_categorical_size = 2,    vocab_static_size       = c(3, 4),    vocab_dynamic_size      = 6,    optimizer               = 'adam',    hidden_dim              = 12,    state_size              = 7,    n_heads                 = 10,    dropout_rate            = 0.1,    output_size             = 3    #quantiles               = 0.5 ) #> Error in py_call_impl(x, dots$args, dots$keywords): RuntimeError: Evaluation error: object 'True' not found."},{"path":"/reference/ts_generator.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a generator — ts_generator","title":"Create a generator — ts_generator","text":"Create generator","code":""},{"path":"/reference/ts_generator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a generator — ts_generator","text":"","code":"ts_generator()"}]
