% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/layer-tcn.R
\name{layer_tcn}
\alias{layer_tcn}
\title{Residual block for the WaveNet TCN}
\usage{
layer_tcn(
  object,
  nb_filters = 64,
  kernel_size = 3,
  nb_stacks = 1,
  dilations = c(1, 7, 14),
  padding = "causal",
  use_skip_connections = TRUE,
  dropout_rate = 0,
  return_sequences = FALSE,
  activation = "relu",
  kernel_initializer = "he_normal",
  use_batch_norm = FALSE,
  use_layer_norm = FALSE,
  use_weight_norm = FALSE,
  input_shape = NULL,
  ...
)
}
\arguments{
\item{nb_filters}{The number of convolutional filters to use in this block}

\item{kernel_size}{The size of the convolutional kernel}

\item{padding}{The padding used in the convolutional layers, 'same' or 'causal'.}

\item{dropout_rate}{Float between 0 and 1. Fraction of the input units to drop.}

\item{activation}{The final activation used in o = Activation(x + F(x))}

\item{kernel_initializer}{Initializer for the kernel weights matrix (Conv1D).}

\item{use_batch_norm}{Whether to use batch normalization in the residual layers or not.}

\item{use_layer_norm}{Whether to use layer normalization in the residual layers or not.}

\item{use_weight_norm}{Whether to use weight normalization in the residual layers or not.}

\item{dilation_rate}{The dilation power of 2 we are using for this residual block}
}
\description{
Residual block for the WaveNet TCN
}
