% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/layer-tcn.R
\name{layer_tcn}
\alias{layer_tcn}
\title{Residual block for the WaveNet TCN}
\usage{
layer_tcn(
  object,
  nb_filters = 64,
  kernel_size = 3,
  nb_stacks = 1,
  dilations = c(1, 7, 14),
  padding = "causal",
  use_skip_connections = TRUE,
  dropout_rate = 0,
  return_sequences = FALSE,
  activation = "relu",
  kernel_initializer = "he_normal",
  use_batch_norm = FALSE,
  use_layer_norm = FALSE,
  use_weight_norm = FALSE,
  input_shape = NULL,
  ...
)
}
\arguments{
\item{nb_filters}{The number of convolutional filters to use in this block}

\item{kernel_size}{The size of the convolutional kernel}

\item{padding}{The padding used in the convolutional layers, 'same' or 'causal'.}

\item{dropout_rate}{Float between 0 and 1. Fraction of the input units to drop.}

\item{activation}{The final activation used in o = Activation(x + F(x))}

\item{kernel_initializer}{Initializer for the kernel weights matrix (Conv1D).}

\item{use_batch_norm}{Whether to use batch normalization in the residual layers or not.}

\item{use_layer_norm}{Whether to use layer normalization in the residual layers or not.}

\item{use_weight_norm}{Whether to use weight normalization in the residual layers or not.}

\item{dilation_rate}{The dilation power of 2 we are using for this residual block}
}
\description{
This is a block composed i.a. from causal convolutional layers.
It may be considered as a replacement for the recurrent layers.
}
\examples{
\donttest{
inp <- layer_input(c(28, 3))
tcn <- layer_tcn()(inp)
model <- keras_model(inp, tcn)
model(array(1, c(32, 28, 3)))
}
}
\references{
\enumerate{
\item \href{https://github.com/philipperemy/keras-tcn}{Keras TCN library by Philippe RÃ©my}
\item Sh. Bai.,  J.Z Kolter, V. Koltun, An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling](https://arxiv.org/abs/1803.01271) (2018)
}
}
