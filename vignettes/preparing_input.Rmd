---
title: "Preparing input for time series models"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{preparing_input}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width=6, 
  fig.height=4
)
```

In this vignette we'll see, how to prepare an input to the time series deep learning models.
To do so quickly, we'll use functions from `{aion}` package.

```{r setup}
library(data.table)
library(dplyr, warn.conflicts = FALSE)
library(aion)
library(keras)
library(tsibbledata)
library(recipes, warn.conflicts = FALSE)
library(ggplot2)

set.seed(7)
```

We feed a `{keras}` models in two ways, using:

* **arrays**
* **generators**
 
Below I present, how to prepare both types of inputs/outputs using `{aion}`.

## Data analysis

As an example we'll the `global_economy` dataset from the `{tsibbledata}` package.

`global_economy` is a n example of **panel dataset**. It simply means that in contains multiple
time series, distinguished with **Country** What we'd like to do, after optional preprocessing such as scaling, imputation etc. is to create a set of arrays (tensors) or a generator, which serves respective batch-level tensors on fly.

```{r data}
head(global_economy)
```

```{r dates}
summary(global_economy$Year)
```


```{r sample_plots}
glob_econ <- as.data.table(global_economy)

sample_countries <- sample(unique(global_economy$Country), 4)

ggplot(glob_econ[Country %in% sample_countries]) +
  geom_line(aes(Year, GDP)) +
  facet_wrap(vars(Country), scales = 'free_y')
```

## Data preprocessing

```{r preprocess}
split_year <- 2000

ge_recipe <- 
  recipe(GDP ~ . , data = glob_econ) %>% 
  step_mutate(Country_idx = Country) %>% 
  step_integer(Country_idx) %>% 
  prep()

train <- 
  glob_econ[Year <= split_year] %>% 
  bake(ge_recipe, .)

test <- 
  glob_econ[Year > split_year] %>% 
  bake(ge_recipe, .)
```

## Arrays

Typically, in the time series forecasting field, we can distiguish the following types of variables:

* **past values of the target variable** 
* **future values of the target variable** 
* **past dynamic features** (numeric and categorical)
* **future dynamic features** (numeric and categorical)
* **static features** (numeric and categorical)

Past target values can be simply treated as a part of the tensor of the past dynamic features.


The simplest possible scenario is to split the dataset using certain date.
```{r}
KEY         <- 'Country'
INDEX       <- 'Year'
TARGET      <- 'GDP'
NUMERIC     <- c('Growth', 'CPI', 'Imports', 'Exports', 'Population')
CATEGORICAL <- 'Country_idx'
STATIC      <- 'Country_idx'

LOOKBACK <- 10
HOIRZON  <- 5

train_arrays <-
  make_arrays(
    data        = train,
    key         = KEY,
    index       = INDEX,
    lookback    = LOOKBACK,
    horizon     = HOIRZON,
    stride      = 4,
    shuffle     = TRUE,
    target      = TARGET,
    categorical = CATEGORICAL,
    numeric     = NUMERIC
  )

print(names(train_arrays))
print(dim(train_arrays$x_past_num))
```
As you can see, it contains five types of arrays. One of them, **y_fut** is the target,
while the rest may be used as the model input. To demonstrate, how we can manipulate the 
data with `make_arrays` function, let's add **static variables** and a separarte array
for past `GDP` values.

```{r make_arrays_2}
train_arrays <-
  make_arrays(
    data        = train,
    key         = KEY,
    index       = INDEX,
    lookback    = LOOKBACK,
    horizon     = HOIRZON,
    stride      = 4,
    shuffle     = TRUE,
    target      = TARGET,
    categorical = CATEGORICAL,
    numeric     = NUMERIC,
    static      = STATIC,
    y_past_sep  = TRUE 
  )

print(names(train_arrays))
print(dim(train_arrays$x_past_num))
```

## Generators

```{r generator}
c(train_gen, train_n_steps) %<-%
  ts_generator(
    data        = train,
    key         = KEY,
    index       = INDEX,
    lookback    = LOOKBACK,
    horizon     = HOIRZON,
    stride      = 4,
    shuffle     = TRUE,
    target      = TARGET,
    categorical = CATEGORICAL,
    numeric     = NUMERIC,
    static      = STATIC,
    y_past_sep  = TRUE,
    batch_size  = 32 
  )

print(class(train_gen))
```
As we can see, the output is not list of arrays, but a list of two objects:

* **generator function**  
Returns a batch of training data at every call. After the loop comes to the end,
the counter is reset and the generator starts serving the same data from the beginning again.

* **number of steps**  
An argument required by the `{keras}` methods.

```{r batch}
batch <- train_gen()
names(batch)
print(dim(batch$y_past))
```
We can them pass these arguments to the `fit` function as follows:
```{r keras_model, eval=FALSE}
model %>% 
  fit(
    x = train_gen,
    steps_per_epoch = train_n_steps,
    validation_data = val_gen,
    validation_steps = val_n_steps
  )

model %>% 
  predict(
    x = test_gen,
    steps = test_n_steps
  )
```

